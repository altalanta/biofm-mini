Metadata-Version: 2.4
Name: biofm
Version: 0.1.0.dev1+gaecbc363b
Summary: Laptop-first multimodal foundation model mini-stack for microscopy, scRNA, and clinical data
Author-email: Artemis Folle <artemis@example.com>
License: MIT License
        
        Copyright (c) 2024 Artemis Folle
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
        
Project-URL: Homepage, https://github.com/altalanta/biofm-mini
Project-URL: Documentation, https://altalanta.github.io/biofm-mini
Project-URL: Bug Tracker, https://github.com/altalanta/biofm-mini/issues
Keywords: multimodal,foundation model,microscopy,single-cell,clinical
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: ==3.11.*
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch<2.4,>=2.2
Requires-Dist: torchvision<0.19,>=0.17
Requires-Dist: numpy>=1.23
Requires-Dist: pandas>=2.0
Requires-Dist: scikit-learn>=1.3
Requires-Dist: pydantic>=2.5
Requires-Dist: hydra-core>=1.3
Requires-Dist: pyarrow>=14.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: typer>=0.9
Requires-Dist: rich>=13.7
Requires-Dist: tqdm>=4.66
Requires-Dist: Pillow>=10.0
Requires-Dist: packaging>=23.0
Provides-Extra: dev
Requires-Dist: pytest>=8.1; extra == "dev"
Requires-Dist: pytest-cov>=4.1; extra == "dev"
Requires-Dist: pytest-mock>=3.12; extra == "dev"
Requires-Dist: coverage[toml]>=7.4; extra == "dev"
Requires-Dist: ruff>=0.2; extra == "dev"
Requires-Dist: black>=24.4; extra == "dev"
Requires-Dist: isort>=5.12; extra == "dev"
Requires-Dist: mypy>=1.8; extra == "dev"
Requires-Dist: pre-commit>=3.6; extra == "dev"
Requires-Dist: types-Pillow; extra == "dev"
Requires-Dist: types-PyYAML; extra == "dev"
Provides-Extra: docs
Requires-Dist: mkdocs>=1.5; extra == "docs"
Requires-Dist: mkdocs-material>=9.5; extra == "docs"
Requires-Dist: mkdocstrings[python]>=0.24; extra == "docs"
Requires-Dist: mkdocs-gen-files>=0.5; extra == "docs"
Requires-Dist: mkdocs-literate-nav>=0.6; extra == "docs"
Provides-Extra: gpu
Requires-Dist: torch<2.4,>=2.2; extra == "gpu"
Requires-Dist: torchvision<0.19,>=0.17; extra == "gpu"
Requires-Dist: torchaudio<2.4,>=2.2; extra == "gpu"
Provides-Extra: viz
Requires-Dist: matplotlib>=3.8; extra == "viz"
Requires-Dist: plotly>=5.18; extra == "viz"
Provides-Extra: scanpy
Requires-Dist: scanpy>=1.9; extra == "scanpy"
Requires-Dist: anndata>=0.9; extra == "scanpy"
Dynamic: license-file

# biofm-mini

[![CI](https://github.com/altalanta/biofm-mini/actions/workflows/ci.yml/badge.svg)](https://github.com/altalanta/biofm-mini/actions/workflows/ci.yml)
[![Coverage](https://img.shields.io/badge/coverage-≥80%25-brightgreen.svg)](https://github.com/altalanta/biofm-mini)

biofm-mini demonstrates a laptop-friendly multimodal foundation model workflow that pairs microscopy tiles, scRNA-seq profiles, and binary clinical labels. end-to-end data wrangling, FM-style contrastive pretraining, and reproducible evaluation across imaging and omics.

## Quickstart in Three Commands
```
make setup
make train
make eval
```
Each command runs in under ten minutes on CPU-only laptops by default. `make train` falls back to toy data and mixed precision automatically uses AMP when CUDA is present.

## Data Schema & Layout
- `data/raw/microscopy/`: PNG/TIF tiles (`sample_id.png`)
- `data/raw/scrna/`: per-sample CSV or `.h5ad` matrices with gene × count values
- `data/raw/clinical/clinical.csv`: tabular metadata with `sample_id`, `label`, `age`, `sex`, plus optional columns
- `data/processed/`: embeddings exported as Parquet; additional artefacts may be added alongside

All raw modalities are validated with pydantic schemas (`MicroscopySample`, `ScrnaSample`, `ClinicalRecord`) and combined via `DatasetBundle`. Schema counts and ranges are checked before training, and loaders gracefully degrade if `scanpy`/`anndata` are absent.

## Swap In Real Datasets
1. Drop microscopy tiles, scRNA-seq matrices, and clinical CSVs into `data/raw/...` matching the schema above.
2. Run `python scripts/prep_data.py --mode real --input-dir data` to validate shape, counts, and metadata.
3. Adjust configs (e.g. `configs/data/real.yaml`, `configs/train/lora.yaml`) to reflect image size, HVG cutoffs, or LoRA fine-tuning preferences and rerun the Make targets.

## Docker (CPU)

Run the full pipeline in a containerized environment:

```bash
docker build -t biofm-mini:cpu -f Dockerfile.cpu .
docker run --rm biofm-mini:cpu
```

This builds a CPU-only container, installs dependencies, and runs `make train && make eval`.

## Open Science Checklist
- ✅ MIT License
- ✅ Reproducible env (`pyproject.toml`, Dockerfile, Makefile)
- ✅ Automated lint/type/test via pre-commit + GitHub Actions
- ✅ Documented data schema, model card, dataset sheet
- ✅ Synthetic fallback data for transparent benchmarking
- ✅ Easy path to plug external datasets (no vendor lock-in)

## Repo Map & Allen Institute Alignment
- `src/biofm/datamodels.py`: strict schemas and dataset validation for imaging, scRNA, and clinical tables
- `src/biofm/dataio/`: modality-aware loaders (microscopy augmentation, Scanpy-aware RNA ingestion, clinical QA, synthetic toy data)
- `src/biofm/models/`: ResNet18 encoder, RNA MLP, CLIP head, optional LoRA stubs
- `src/biofm/training/`: reproducible training loop with AMP, grad clipping, checkpoints
- `src/biofm/eval/`: linear probe with AUROC/AUPRC + bootstrap CIs, decision curve utilities
- `src/biofm/preprocess/`: tiling/normalisation and scRNA filtering helpers
- `src/biofm/utils/`: registries, seeding, embedding export
- `scripts/`: `prep_data`, `train`, `embed`, `eval` Hydra-aware entrypoints
- `configs/`: hydra defaults plus data/train/eval overrides for toy vs. real workflows
- `tests/`: unit coverage for toy data, schemas, model step, and metrics

## Governance

This project follows responsible AI and open science practices:

- **[MODEL_CARD.md](MODEL_CARD.md)**: Details model architecture, intended use, limitations, and risks
- **[DATASET_SHEET.md](DATASET_SHEET.md)**: Documents data sources, collection methods, and known biases

Additional governance documentation:
- [CONTRIBUTING.md](CONTRIBUTING.md): Contribution guidelines and development practices  
- [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md): Community standards and behavior expectations

### How this maps to the role
- Contribute to ML models… (data wrangling/curation/validation)
- Lead data management, software infrastructure and AI/ML workflow best practices and policies
- Participate in institute-wide initiatives…
- Promote open science…
- Advance community standards for scalability…
- Foster a collaborative and inclusive work environment…
